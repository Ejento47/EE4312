{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQyXvwtncL1-"
      },
      "source": [
        "# EE4312 Lab 1 *Regression*\n",
        "Due Date: 14 Feb 2025 (W5 Fri), 23:59"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqzA-acbpLZV"
      },
      "source": [
        "---\n",
        "# 1 $\\quad$ Introduction\n",
        "Regression is all about finding a quantitative output $y$ from an input variable $x$. A regression problem focuses on using a neural network to approximate the relationship between $y(x)$ and $x$, which is learnt from noisy sampled data $\\tilde{y}(x)$.\n",
        "\n",
        "In this lab, the output $y$ is the response of a system that is randomized based on your matric number. 71 noisy measurements were made for $x\\in[0,7]$. The task is to build a 1-layer neural network with Keras, and approximate the response."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 $\\quad$ Initialization\n",
        "1. Replace the string in `matric_numbers` with your matric number.\n",
        "2. Run the code block (`Ctrl+Enter`)."
      ],
      "metadata": {
        "id": "JpY_Afosj0bg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "matric_numbers = ['A0135834J']\n",
        "\n",
        "######### Import libraries ###################\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import keras\n",
        "from tqdm.keras import TqdmCallback\n",
        "from google.colab import files\n",
        "\n",
        "########## Code to make training reproducible ##########\n",
        "def makeSeed(matric_numbers):\n",
        "  seed = 0;\n",
        "  for i in range(len(matric_numbers)):\n",
        "    seed += int(''.join(filter(str.isdigit, matric_numbers[i])))\n",
        "  print(f'  Seed: {seed}')\n",
        "  return seed\n",
        "\n",
        "SEED = makeSeed(matric_numbers)\n",
        "\n",
        "def makeReproducible():\n",
        "  tf.keras.utils.set_random_seed(SEED)\n",
        "  tf.config.experimental.enable_op_determinism()\n",
        "\n",
        "########### Create Folders to store trained data #############\n",
        "R_FOLDER = 'data/lab1'\n",
        "\n",
        "!rm -rf $R_FOLDER # removes the folder. this is not a valid python script, used only in colab\n",
        "!mkdir -p $R_FOLDER # this is not a valid python script, used only in colab\n",
        "\n",
        "###### Define Constants #####\n",
        "R_MIN_TEST_X = 0\n",
        "R_MIN_TRAIN_X = 0\n",
        "R_MAX_TRAIN_X = 7\n",
        "R_MAX_TEST_X = 7\n",
        "R_NUM_POINTS = 71\n",
        "\n",
        "###### Variables to be initialized later, placed here for clarity ##########\n",
        "r_model = None\n",
        "r_expt_name = ''\n",
        "r_num_hidden = 0\n",
        "r_learning_rate = 0\n",
        "r_epochs = 0\n",
        "r_batch_size = 0\n",
        "r_elapsed = 0\n",
        "r_history = None\n",
        "r_train_indices = None\n",
        "r_x_test = []\n",
        "r_y_test = [] # the true y over the domain of x_test\n",
        "r_x_train = [] # the x data, that has a smaller domain than x_test\n",
        "r_y_train = [] # the noisy y over the domain of x_train\n",
        "r_y_pred = []\n",
        "r_tau = 0\n",
        "\n",
        "##### Initialize the variables ########\n",
        "def rInit():\n",
        "  r_tau = np.random.uniform(0.7, 0.8) if np.random.uniform() > 0.5 else np.random.uniform(1.1, 1.3)\n",
        "  print(f'tau: {r_tau}')\n",
        "  r_x_test = np.linspace(R_MIN_TEST_X, R_MAX_TEST_X, R_NUM_POINTS).reshape(-1, 1)\n",
        "  r_y_test = np.sin(r_x_test * r_tau * 3) * np.exp(r_x_test *-1)\n",
        "  r_train_indices = (r_x_test >= R_MIN_TRAIN_X) & (r_x_test <= R_MAX_TRAIN_X)\n",
        "  r_train_indices = np.array(r_train_indices).reshape(-1)\n",
        "  r_x_train = r_x_test[r_train_indices]\n",
        "  r_y_train = r_y_test[r_train_indices]\n",
        "  r_y_train = r_y_train + np.random.normal(0.0, 0.03, r_y_train.shape)\n",
        "  return r_tau, r_train_indices, r_x_test, r_y_test, r_x_train, r_y_train\n",
        "\n",
        "##### Plot the Regression Task #######\n",
        "def rPlotTask():\n",
        "  fig, ax = plt.subplots()\n",
        "  ax.axhspan(-0.08, 0.08, alpha=0.2, color='grey') # steady state\n",
        "  ax.plot(r_x_test, r_y_test, '--', alpha=0.5, label='True')\n",
        "  ax.plot(r_x_train, r_y_train, 'b.-', alpha=0.5, label='Training Data')\n",
        "  ax.grid(True, which='both', axis='both')\n",
        "  ax.legend();\n",
        "  ax.set_title(f'Regression Task, tau = {r_tau:.2f}, seed = {SEED}')\n",
        "  ax.grid(visible=True)\n",
        "  fig.set_size_inches(12.0, 4.0)\n",
        "  fig.savefig(f'{R_FOLDER}/task.png', dpi=100)\n",
        "\n",
        "##### Run the functions ##########\n",
        "makeReproducible() # call this everytime to 'reset' the random number generator and make subsequent random calls reproducible.\n",
        "r_tau, r_train_indices, r_x_test, r_y_test, r_x_train, r_y_train = rInit()\n",
        "rPlotTask()"
      ],
      "metadata": {
        "id": "Lh8c6_qCCroo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 $\\quad$ Ignore Oscillations at Steady State\n",
        "The response is considered to be at steady state at $x=d$ if $|y(x)|$ is expected to be smaller than $0.08$ for all $x \\ge d$. The values of $y$ satisfying the criterion is depicted as the gray region in the plot above.\n",
        "\n",
        "Take note that if $y(x)$ is expected to be in steady state after $x=d$, any **oscillations after $x=d$ can be ignored** when designing the neural network."
      ],
      "metadata": {
        "id": "WcfyA_JCkaIA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# 2$\\quad$ Code the Regression Model"
      ],
      "metadata": {
        "id": "TZaORc-Jl4eo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 $\\quad$ Function that Builds the Model\n",
        "\n",
        "Specify the design of the neural network in `r_model`, which will be returned by the function `rBuildModel()`.\n",
        "\n",
        "1. **Initialize the layers**. The input layer, a hidden layer, and an output layer is required. For the hidden layer, use the variable `r_num_hidden` to specify the number of hidden neurons.\n",
        "  ```python\n",
        "  input_layer = keras.Input(shape=??) # ?? is tuple specifying the input dimensions.\n",
        "  hidden_layer = keras.layers.Dense(??, activation=????) # ?? is the number of neurons. # ???? is a string specifying the activation function\n",
        "  output_layer = keras.layers.Dense(??, activation=????) # ?? is the number of neurons. # ???? is a string specifying the activation function\n",
        "  ```\n",
        "2. **Link the layers** by calling the layer variables (i.e. using `()`) with their previous layer. e.g.\n",
        "  ```python\n",
        "  output_layer = output_layer(hidden_layer(input_layer))\n",
        "  ```\n",
        "3. **Initialize the model** `r_model` with the linked layers:\n",
        "  ```python\n",
        "  r_model = keras.Model(inputs=[input_layer], outputs=[output_layer], name='Regression')\n",
        "  ```\n",
        "4. **Compile the model** with the selected loss and optimizer:\n",
        "  ```python\n",
        "  sgd = keras.optimizers.SGD(learning_rate=r_learning_rate)\n",
        "  r_model.compile(loss='??', optimizer=sgd) # ?? is the name of the loss used in regression.\n",
        "  ```\n",
        "  *You may notice that the loss can be specified using `keras.losses.???` instead of a string, and similarly for the optimizer. Either way (string or Keras object) is acceptable.*\n",
        "5. Next, print a summary of the model to the output using\n",
        "  ```python\n",
        "  r_model.summary()\n",
        "  ```\n",
        "6. The model is then returned by the function. **Run** the cell block to register the function into the workspace, and fix any syntax errors that show up.  *Note the function will not run for now. Further errors will only be discovered later when we run this function and the subsequent functions in a later code cell.*\n",
        "\n"
      ],
      "metadata": {
        "id": "tLxv0NT6nhno"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rBuildModel():\n",
        "  ###### Specify the layers #####\n",
        "  # (1)\n",
        "\n",
        "  ###### Link the layers #####\n",
        "  # (2)\n",
        "\n",
        "  ###### Initialize model #####\n",
        "  # (3)\n",
        "\n",
        "  ###### Compile model #####\n",
        "  # (4)\n",
        "\n",
        "  ###### Summarize #####\n",
        "  # (5)\n",
        "\n",
        "\n",
        "  print(f'----------------------------------')\n",
        "  return r_model"
      ],
      "metadata": {
        "id": "ykBWZNKge264"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 $\\quad$ Function that Trains the Model\n",
        "The code to train the model is defined in the function `rTrainModel()`.\n",
        "\n",
        "1. In the function, the `.fit()` method is used to train the model `r_model`:\n",
        "```python\n",
        "r_history = r_model.fit(???, # the x samples used for training.\n",
        "                        ???, # the y samples used for training.\n",
        "                        shuffle=True,\n",
        "                        batch_size=???, # the batch size.\n",
        "                        epochs=???, # the number of epochs.\n",
        "                        validation_split=0,\n",
        "                        verbose=0,\n",
        "                        callbacks=[TqdmCallback(verbose=0)],\n",
        "                        ) # this is a single line-command split over multiple lines for readability.\n",
        "```\n",
        "  The code above requires:\n",
        "  - The input $x$ samples stored in `r_x_train`.\n",
        "  - The measured $\\tilde{y}$ samples stored in `r_y_train`.\n",
        "  - The batch size stored in `r_batch_size`.\n",
        "  - The number of epochs to train in `r_epochs`.\n",
        "\n",
        "  `r_history` stores information about the training. `r_elapsed` is the time taken to train the model in seconds. `r_model` will contain the trained weights and can be used to predict an input layer. The three variables are returned by the function.\n",
        "\n",
        "2. **Run** the code block to register the function and fix any errors."
      ],
      "metadata": {
        "id": "EEr_KSRLtzXX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rTrainModel():\n",
        "  ########### Train the Model #########\n",
        "  print(f'    Experiment: {r_expt_name}\\nHidden Neurons: {r_num_hidden}\\n Learning Rate: {r_learning_rate}\\n        Epochs: {r_epochs}\\n    Batch Size: {r_batch_size}')\n",
        "  r_elapsed = time.time()\n",
        "\n",
        "  # (1)\n",
        "\n",
        "  r_elapsed = time.time() - r_elapsed\n",
        "\n",
        "  ########### Save the model ###########\n",
        "  r_model.save(f'{R_FOLDER}/{r_expt_name}.keras')\n",
        "  print(f'Trained Model saved to {R_FOLDER}/{r_expt_name}.keras')\n",
        "\n",
        "  return r_model, r_history, r_elapsed"
      ],
      "metadata": {
        "id": "dh5jm3Pup4BO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3 $\\quad$ Function that Predicts using Trained Model\n",
        "The code to find the predicted output $\\tilde{y}$ with the trained model is designed in the function `rPredictModel()`.\n",
        "\n",
        "1. The method `.predict()` is used to predict the output from the trained model `r_model`:\n",
        "```python\n",
        "  ?? = r_model.predict(????) # ?? is the predicted output. ???? is the input used to predict the output.\n",
        "```\n",
        "  In this implementation, the output is predicted over the domain of the training data:\n",
        "  - The trained input $x$ is stored in `r_x_train`.\n",
        "  - The predicted output $\\tilde{y}$ must be stored in `r_y_pred`, which is returned by the function\n",
        "2. **Run** the code block to register the function and fix any errors.\n"
      ],
      "metadata": {
        "id": "L0dEoZbTxxoI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rPredictModel():\n",
        "  # (1)\n",
        "\n",
        "  return r_y_pred"
      ],
      "metadata": {
        "id": "RyiKLml6qFOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.4 $\\quad$ Function that Analyzes the Trained Model\n",
        "The function `rAnalyzeModel()` saves performance-related data, trained weights, and hyperparameters in a text file, and visualizes them.\n",
        "\n",
        "1. When `rTrainModel()` is run, the loss that is displayed in the output refers to the **moving average calculated over multiple batches**. Instead, we are intersted in the loss that is calculated instead over the **entire** measured output $\\tilde{y}$ and true output $y$:\n",
        "```python\n",
        "loss = keras.losses.??() # ?? is a function, not a string, of the loss used above.\n",
        "train_loss = loss(??, ????) # ?? is the measured output, ???? is the predicted output\n",
        "test_loss = loss(??, ????) # ?? is the true output, ???? is the predicted output\n",
        "```\n",
        "  - The true output $y$ is stored in `r_y_test`.\n",
        "  - The predicted output $\\hat{y}$ is stored in `r_y_pred`.\n",
        "  - The measured output $\\tilde{y}$ is stored in `r_y_train`.\n",
        "\n"
      ],
      "metadata": {
        "id": "4SIxlOV13YL2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "######### Analyze ###################\n",
        "def rAnalyzeModel(): # put in function to prevent temporary vars from polluting the workspace\n",
        "  ########## Calc loss ##############\n",
        "  # (1)\n",
        "\n",
        "  ########### Plot Predicted output #############\n",
        "  # Predicted output is over the larger r_x_test data.\n",
        "  # training is done over the smaller r_x_train data.\n",
        "  fig, ax = plt.subplots(figsize=(10, 5))\n",
        "  ax.axhspan(-0.08, 0.08, alpha=0.2, color='grey') # steady state\n",
        "  ax.plot(r_x_test, r_y_test, '--', alpha=0.5, label='True')\n",
        "  ax.plot(r_x_train, r_y_train, 'b.-', alpha=0.5, label='Training Data')\n",
        "  ax.plot(r_x_test, r_y_pred, color='red', label='Predicted')\n",
        "  ax.grid(True, which='both', axis='both')\n",
        "  ax.legend();\n",
        "  ax.set_title(f'Regression Results ({r_expt_name})')\n",
        "  ax.grid(visible=True)\n",
        "  fig.set_size_inches(12.0, 4.0)\n",
        "  fig.savefig(f'{R_FOLDER}/{r_expt_name}_results.png', dpi=100, bbox_inches='tight')\n",
        "\n",
        "  ########## Loss Plots #############\n",
        "  fig, axes = plt.subplots(ncols=2, figsize=(10, 5))\n",
        "  # MA Loss\n",
        "  r_history_loss = r_history.history['loss']\n",
        "  axes[0].plot(r_history_loss)\n",
        "  axes[0].set_title(f'Moving Average Loss vs. Epoch ({r_expt_name})')\n",
        "  axes[0].set_ylabel('Moving Average Loss')\n",
        "  axes[0].set_xlabel('Epoch')\n",
        "  axes[0].grid(True, which='both', axis='both');\n",
        "  # Log of MA loss\n",
        "  axes[1].plot(np.log(r_history_loss))\n",
        "  axes[1].set_title(f'Log of Moving Average Loss vs. Epoch ({r_expt_name})')\n",
        "  axes[1].set_ylabel('Log of Moving Average Loss')\n",
        "  axes[1].set_xlabel('Epoch')\n",
        "  axes[1].grid(True, which='both', axis='both')\n",
        "  plt.savefig(f'{R_FOLDER}/{r_expt_name}_loss.png', bbox_inches='tight')\n",
        "\n",
        "  ########## Find the individual and cumulative contribution of neurons =============\n",
        "  # Extract weights and simulate responses\n",
        "  r_l1_weights = r_model.layers[1].get_weights()\n",
        "  r_l1_w1 = r_l1_weights[0] #w\n",
        "  r_l1_w0 = r_l1_weights[1] #bias\n",
        "  # one cell is induced field for each neuron for each sample\n",
        "  r_y_neuron = np.matmul(r_x_test, r_l1_w1) + r_l1_w0 # Nxnum_hidden\n",
        "  # activation (output of first layer) of each sample for each neuron\n",
        "  r_y_neuron = np.tanh(r_y_neuron)\n",
        "\n",
        "  r_l2_weights = r_model.layers[2].get_weights()\n",
        "  r_l2_w1 = np.transpose(r_l2_weights[0]) #w (1xnum_hid)\n",
        "  r_l2_w0 = r_l2_weights[1] #bias\n",
        "  r_y_neuron = r_y_neuron * r_l2_w1 # Nxnum_hid * 1xnum_hid\n",
        "\n",
        "  # Show the contribution of each neuron\n",
        "  fig_nrows = r_num_hidden // 10 + (r_num_hidden % 10 != 0)\n",
        "  fig, axes = plt.subplots(nrows=fig_nrows, ncols=10, figsize=(20, fig_nrows * 2.0))\n",
        "  fig.subplots_adjust(top=0.75)\n",
        "  i = 0\n",
        "  for ax in fig.axes:\n",
        "    if i >= r_num_hidden:\n",
        "      ax.axis('off')\n",
        "      continue\n",
        "    ax.plot(r_x_test, r_y_neuron[:, i])\n",
        "    ax.grid(True, 'both', 'both')\n",
        "    i += 1\n",
        "    ax.set_title('$w^{(2)}_{1,%d}y^{(1)}_{%d}$' % (i, i))\n",
        "  fig.suptitle(f'Individual Contribution of Hidden Neurons ({r_expt_name})', x=0.2, y=0.98)\n",
        "  plt.savefig(f'{R_FOLDER}/{r_expt_name}_contribution.png', bbox_inches='tight')\n",
        "\n",
        "  fig, axes = plt.subplots(nrows=fig_nrows, ncols=10, figsize=(20, fig_nrows * 2.3))\n",
        "  fig.subplots_adjust(top=0.65)\n",
        "  i = 0\n",
        "  r_y_neur_cum = np.zeros(r_y_test.shape)\n",
        "  for ax in fig.axes:\n",
        "    if i >= r_num_hidden:\n",
        "      ax.axis('off')\n",
        "      continue\n",
        "    r_y_neur_cum[:, 0] += r_y_neuron[:, i]\n",
        "    ax.plot(r_x_test, r_y_neur_cum)\n",
        "    ax.grid(True, 'both', 'both')\n",
        "    i += 1\n",
        "    ax.set_title('$\\sum_{i=1}^{%d} w^{(2)}_{1,i}y^{(1)}_{i}$' % i)\n",
        "  fig.suptitle(f'Cumulative Contribution of Hidden Neurons ({r_expt_name})', x=0.2, y=0.98)\n",
        "  plt.savefig(f'{R_FOLDER}/{r_expt_name}_cumulative.png', bbox_inches='tight')\n",
        "\n",
        "  #### Write to text file ####\n",
        "  tmp = open(f'{R_FOLDER}/{r_expt_name}.txt', 'w')\n",
        "  # Print weights\n",
        "  out = ''\n",
        "  out += f'Experiment\\t{r_expt_name}\\n'\n",
        "  out += f'Hidden Neurons\\t{r_num_hidden}\\n'\n",
        "  out += f'Learning Rate\\t{r_learning_rate}\\n'\n",
        "  out += f'Epochs\\t{r_epochs}\\n'\n",
        "  out += f'Batch\\t{r_batch_size}\\n'\n",
        "  out += f'Elapsed(s)\\t{r_elapsed}\\n'\n",
        "  for i in range(1, 11):\n",
        "    out += f'Moving Average Loss ({i}0% Epoch)\\t{r_history_loss[int(0.1 * i * len(r_history_loss) - 1)]}\\n'\n",
        "  out += f'Train Loss\\t{train_loss}\\n'\n",
        "  out += f'True Loss\\t{test_loss}\\n'\n",
        "\n",
        "  out += 'Weights:\\n'\n",
        "  for i in range(r_num_hidden): # first layer\n",
        "    out += ('w^{(1)}_%d\\t%5.2f\\t%5.2f\\n' % (i + 1, r_l1_w0[i], r_l1_w1[0, i]))\n",
        "  out += ('w^{(2)}_1\\t%5.2f' % r_l2_w0[0])  # output bias\n",
        "  for i in range(r_num_hidden): # output\n",
        "    out += '\\t%5.2f' % r_l2_w1[0, i]\n",
        "  out += '\\n'\n",
        "\n",
        "  tmp.write(out)\n",
        "  tmp.close()\n",
        "  print(out)"
      ],
      "metadata": {
        "id": "VKhNPbip6zh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# 3 $\\quad$ Run the Regression Model\n",
        "\n",
        "1. Test your code above by running the following. If there are errors:\n",
        "  1. Go to the function and fix the error.\n",
        "  2. **Always run** the code block containing the **modified function** to register the modifications.\n",
        "2. Once all errors are fixed, you may adjust the `experiments` list to run multiple experiments and observe the effects of adjusting the hyperparameters."
      ],
      "metadata": {
        "id": "272MoTmhK3lD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wy0MgUlxMBRC"
      },
      "outputs": [],
      "source": [
        "# experiments = [\n",
        "#   ('expt name 1', num hidden neurons 1, learn rate 100, epochs 1, batch size 1)\n",
        "#   ('expt name 2', num hidden neurons 2, learn rate 2, epochs 2, batch size 2),\n",
        "#   ...\n",
        "# ]\n",
        "experiments = [\n",
        "  ('a', 15, 0.1, 50, 10),\n",
        "]\n",
        "\n",
        "for expt in experiments:\n",
        "  r_expt_name = expt[0]\n",
        "  r_num_hidden = expt[1]\n",
        "  r_learning_rate = expt[2]\n",
        "  r_epochs = expt[3]\n",
        "  r_batch_size = expt[4]\n",
        "\n",
        "  print(f'====================== START OF EXPT {r_expt_name} ====================================')\n",
        "\n",
        "  makeReproducible()\n",
        "  r_model = rBuildModel()\n",
        "\n",
        "  makeReproducible()\n",
        "  r_model, r_history, r_elapsed = rTrainModel()\n",
        "\n",
        "  r_y_pred = rPredictModel()\n",
        "\n",
        "  rAnalyzeModel()\n",
        "\n",
        "  print(f'====================== END OF EXPT {r_expt_name} ======================================')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# 4 $\\quad$ Download Data\n",
        "Run the following code to download all figures and data, which can be used in the report."
      ],
      "metadata": {
        "id": "qyj9YbapLSXs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2BlIcWe-24N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "cba8f1b9-fef7-4318-aa5e-c695617f7874"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: data/ (stored 0%)\n",
            "  adding: data/lab1/ (stored 0%)\n",
            "  adding: data/lab1/a.keras (deflated 88%)\n",
            "  adding: data/lab1/a.txt (deflated 61%)\n",
            "  adding: data/lab1/task.png (deflated 6%)\n",
            "  adding: data/lab1/a_results.png (deflated 5%)\n",
            "  adding: data/lab1/a_loss.png (deflated 11%)\n",
            "  adding: data/lab1/a_cumulative.png (deflated 8%)\n",
            "  adding: data/lab1/a_contribution.png (deflated 7%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6b495904-e0c9-4339-bee8-1a3c7c773476\", \"data.zip\", 288580)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "!rm -rf data.zip\n",
        "!zip -r data.zip data\n",
        "files.download('data.zip')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# 5 $\\quad$ Submission Requirements\n",
        "1. Complete Sections 1 and 2.\n",
        "2. In Section 3, submit the worksheet by specifying **only** the following two experiments and their hyperparameters:\n",
        "```python\n",
        "  experiment = [\n",
        "    ('minimal', ???), # ??? the other hyperparamters\n",
        "    ('suggested', ???), # ??? the other hyperparameters\n",
        "  ]\n",
        "```\n",
        "  1. For the `minimal` experiment, specify the best set hyperparameters to design a network that uses the minimal number of hidden neurons. Change only the number of hidden neurons, the epochs, and the learning rate. The minimal number is the number of changing slope directions until the steady-state. The number of epochs must be less than 10,000. Keep the batch size as 10.\n",
        "\n",
        "  2. For the `suggested` experiment, specify the best set of hyperparameters for a network that has minimal loss over the measured output. Change only the number of hidden neurons, the epochs, and the learning rate. The number of epochs must be less than 10,000, and the number of hidden neurons must be less than three times the minimal number. Keep the batch size as 10.\n",
        "\n",
        "3. Justify your choice for the `minimal` experiment in the box below, by discussing with respect to the activation function and their individual and cumulative contributions.\n",
        "\n",
        "4. Justify your choice for the `suggested` experiment in the box below, by discussing with respect to over-fitting, training time, loss, and the number of weights (trainable parameters).\n",
        "\n",
        "5. **Do not indicate your name anywhere in the file**.\n",
        "\n",
        "6. Rename this file as `L1_<MATRIC>.ipynb` where `<MATRIC>` is your matric in **CAPITAL LETTERS**. For example, `L1_A0123456X.ipynb`, and submit to Canvas `L1` assignment.\n"
      ],
      "metadata": {
        "id": "j5qTN9bjMxYz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Q3 here (double click this)**"
      ],
      "metadata": {
        "id": "xgiHLxpaQJNb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Q4 here (double click this)**"
      ],
      "metadata": {
        "id": "DEKvhkraQJkz"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}